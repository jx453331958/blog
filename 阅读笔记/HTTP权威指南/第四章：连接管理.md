# HTTP 权威指南

## 第 4 章 连接管理

1. TCP 连接：世界上几乎所有的 HTTP 通信都是由 TCP/IP 承载的，TCP/IP 是全球计算机及网络设备都在使用的一种常见的分组交换网络分层协议集。

    1. TCP 的可靠数据管道：TCP 为 HTTP 提供了一条可靠的比特传输管道。从 TCP 连接一端填入的字节会从另一端以原有的顺序、正确地传送出来。
    2. TCP 是分段的、由 IP 分组传送：TCP 的数据是通过名为 IP 分组（或 IP 数据报）的小数据块来发送。
    3. HTTPS 是在 HTTP 和 TCP 之间插入了一个（称为 TLS 或 SSL 的）密码加密层。
    4. HTTP 要传送一条报文时，会以流的形式将报文数据的内容通过一条打开的 TCP 连接按序传输。TCP 收到数据流之后，会将数据流砍称被称作段的小数据块，并将段封装在 IP 分组中，通过因特网进行传输。
    5. 每个 TCP 段都是由 IP 分组承载，从一个 IP 地址发送到另一个 IP 地址的。每个 IP 分组中都包括：
        1. 一个 IP 分组首部（通常为 20 字节）：包含了源和目的 IP 地址、长度和其他一些标记。
        2. 一个 TCP 段首部（通常为 20 字节）：包含了 TCP 端口号、TCP 控制标记，以及用于数据排序和完整性检查的一些数字值。
        3. 一个 TCP 数据块（0 个或多个字节）
    6. 在任意时刻计算机都可以有几条 TCP 连接处于打开状态。TCP 是通过端口号来保持所有这些连接持续不断地运行。
    7. TCP 连接是通过 4 个值来识别的：`<源IP地址、源端口号、目的IP地址、目的端口号>`，这 4 个值一起唯一地定义了一条连接
    8. 对 TCP 连接进行编程所需的常见套接字接口函数：
        1. `s = socket(<parameters>)`：创建一个新的、未命名、未关联的套接字
        2. `bind(s,<local IP:port>)`：向套接字赋一个本地端口号和接口
        3. `connect(s, <remote IP:port>)`：创建一条连接本地套接字与远程主机及端口的连接
        4. `listen(s,...)`：标识一个本地套接字，使其可以合法接受连接
        5. `s2 = accept(s)`：等待某人建立一条到本地端口的连接
        6. `n = read(s, buffer, n)`：尝试从套接字向缓冲区读取 n 个字节
        7. `n = write(s, buffer, n)`：尝试从缓冲区中向套接字写入 n 个字节
        8. `close(s)`：完全关闭 TCP 连接
        9. `shutdown(s,<side>)`：只关闭 TCP 连接的输入或输出端
        10. `getsockopt(s,...)`：读取某个内部套接字配置选项的值
        11. `setsockopt(s,...)`：修改某个内部套接字配置选项的值
    9. 套接字 API 允许用户创建 TCP 的端点数据结构，将这些端点与远程服务器的 TCP 端点进行连接，并对数据流进行读写。
    10. TCP API 隐藏了所有底层网络协议的握手细节，以及 TCP 数据流与 IP 分组之间的分段和重装细节。

2. 对 TCP 性能的考虑：HTTP 位于 TCP 的上层，HTTP 事务的性能在很大程度上取决于底层 TCP 通道的性能。

    1. HTTP 事务的时延的主要原因：这些 TCP 网络时延的大小取决于硬件速度、网络和服务器负载，请求和响应报文的尺寸，以及客户端和服务器之间的距离。TCP 协议的技术复杂性也会对时延产生巨大的影响。
        1. 客户端首先需要根据 URI 确定服务器的 IP 地址和端口号。如果最近没有对 URI 中的主机名进行访问，通过 DNS 解析系统将 URI 中的主机名转换成一个 IP 地址可能要花费数十秒的时间。
        2. 客户端会向服务器发送一条 TCP 连接请求，并等待服务器回送一个请求接受应答。每条新的 TCP 连接都会有连接建立时延。
        3. 连接建立起来之后，客户端会通过新建立的 TCP 管道来发送 HTTP 请求，数据到达时，服务器会从 TCP 连接中读取请求报文，并对请求进行处理。因特网传输请求报文以及服务器处理请求报文都需要时间。
        4. 服务器回送 HTTP 响应，需要花费时间。
    2. 性能聚焦区域：其他常见 TCP 相关时延
        1. TCP 连接建立握手
        2. TCP 慢启动拥塞控制
        3. 数据聚集的 Nagle 算法
        4. 用于捎带确认的 TCP 延迟确认算法
        5. TIME_WAIT 时延和端口耗尽
    3. TCP 连接的握手时延：建立一条新的 TCP 连接时，甚至是在发送任意数据之前，TCP 软件之间会交换一系列的 IP 分组，对连接的有关参数进行沟通。如果连接只用于传送少量数据，这些交换过程就会严重降低 HTTP 的性能。
    4. TCP 连接握手需要经过以下几个步骤：
        1. 请求新的 TCP 连接时，客户端要向服务器发送一个小的 TCP 分组。这个分组中设置了一个特殊的 SYN 标记，说明这是一个连接请求。
        2. 如果服务器接受了请求，就会对一些连接参数进行计算，并向客户端回送一个 TCP 分组，这个分组中的 SYN 和 ACK 标记都被置位，说明连接请求已经被接受。
        3. 最后，客户端向服务器回送一条确认信息，通知它连接已成功建立。现代的 TCP 栈都允许客户端在这个确认分组中发送数据。
    5. 通常 HTTP 事务都不会交换太多数据，此时，SYN/SYN+ACK 握手会产生一个可测量的时延。TCP 连接的 ACK 分组通常都足够大，可以承载整个 HTTP 请求报文，而且很多 HTTP 服务器响应报文都可以放入一个 IP 分组中去。
    6. 小的 HTTP 事务可能会在 TCP 建立上花费 50%或更多的时间。通过重用现存连接，可以减小这种 TCP 建立时延所造成的影响。
    7. 由于因特网自身无法确保可靠的分组传输，所以 TCP 实现了自己的确认机制来确保数据的成功传输。
    8. 每个 TCP 段都有一个序列号和数据完整性校验和。每个段的接收者收到完好的段时，都会向发送者回送小的确认分组。如果发送者没有在指定的窗口时间内收到确认信息，发送者就会认为分组已经被破坏或损毁，并重发数据。
    9. 由于确认报文很小，所以 TCP 允许在发往相同方向的输出数据分组中对其进行“捎带”。TCP 将返回的确认信息与输出的数据分组结合在一起，可以更有效地利用网络。
    10. 延迟确认算法：为了增加确认报文找到同向传输数据分组的可能性，很多 TCP 栈都实现了一种“延迟确认”算法。延迟确认算法会在一个特定的窗口时间内（通常是 100 ～ 200 毫秒）将输出确认存放在缓冲区中，以寻找能够捎带它的输出数据分组。如果在那段时间内没有输出数据分组，就将确认信息放在单独的分组中传送。
    11. TCP 慢启动：TCP 数据传输的性能还取决于 TCP 连接的使用期。TCP 连接会随着时间进行自我“调协”，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调协被称为 TCP 慢启动，用于防止因特网的突然过载和拥塞。
    12. 打开拥塞窗口：TCP 慢启动限制了一个 TCP 端点在任意时刻可以传输的分组数。如果某个 HTTP 事务有大量数据要发送，是不能一次将所有分组都发送出去的。必须发送一个分组，等待确认，然后可以发送两个分组，每个分组都必须被确认，这样就可以发送四个分组了，以此类推。这种方式称为“打开拥塞窗口”。
    13. 由于存在这种拥塞控制特性，所以新连接的传输速度会比已经交换过一定量数据的、“已调谐”连接慢一些。由于已调协连接更快一些，所以 HTTP 中有一些可以重用现存连接的工具。
    14. Nagle 算法与 TCP_NODELAY：每个 TCP 段中都至少装载了 40 个字节的标记和首部，如果 TCP 发送了大量包含少量数据的分组，网络的性能就会严重下降。Nagle 算法试图在发送一个分组之前，将大量 TCP 数据绑在一起，以提高网络效率。Nagle 算法鼓励发送全尺寸的段。只有当所有其他分组都被确认之后，Nagle 算法才允许发送非全尺寸的分组。如果其他分组仍然在传输过程中，就将那部分数据缓存起来。只有当挂起分组被确认，或者缓冲区中积累了足够发送一个全尺寸分组的数据时，才会将缓存的数据发送出去。
    15. Nagle 算法引起的 HTTP 性能问题：
        1. 小的 HTTP 报文可能无法填满一个分组，可能会因为等待那些永远也不会到来的额外数据而产生时延。
        2. Nagle 算法与延迟确认之间的交互存在问题，Nagle 算法会阻止数据的发送，直到有确认分组抵达为止，但确认分组自身会被延迟确认算法延迟 100 ～ 200 毫秒。
    16. HTTP 应用程序常常会在自己的栈中设置参数 TCP_NODELAY，禁用 Nagle 算法，提高性能。

3. HTTP 连接的处理

    1. HTTP 允许在客户端和最终的源端服务器之间存在一串 HTTP 中间实体（代理、高速缓存等）。
    2. 在某些情况下，两个相邻的 HTTP 应用程序会为它们共享的连接应用一组选项，HTTP 的 Connection 首部字段中有一个由逗号分隔的连接标签列表，这些标签为此连接制定了一些不会传播到其他连接中去的选项。
    3. Connection 首部可以承载 3 种不同类型的标签：
        1. HTTP 首部字段名，列出了只与此连接有关的首部
        2. 任意标签值，用于描述此连接的非标准选项
        3. 值 close，说明操作完成之后需要关闭这条持久连接
    4. HTTP 应用程序收到一条带有 Connection 首部的报文时，接收端会解析发送端请求的所有选项，并将其应用。然后会将此报文转发给下一跳地址之前，删除 Connection 首部以及 Connection 中列出的所有首部。
    5. 提升 HTTP 性能的四类技术：
        1. 并行连接：通过多条 TCP 连接发起并发的 HTTP 请求
        2. 持久连接：重用 TCP 连接，以消除连接及关闭时延
        3. 管道化连接：通过共享的 TCP 连接发起并发的 HTTP 请求
        4. 复用的连接：交替传送请求和响应报文

4. 并行连接

    1. HTTP 允许客户端打开多条连接，并行地执行多个 HTTP 事务。
    2. 并行连接可能会提高页面的加载速度。
    3. 并行连接不一定更快：客户端的网络宽带不足的时，大部分的时候可能都是用来传递数据的。这种情况下，一个连接到速度较快服务器上的 HTTP 事务就会很容易地耗尽所有可用的带宽。如果并行加载多个对象，每个对象都会去竞争这有限的带宽，每个对象都会以较慢的速度按比例加载，这样带来的性能提升就很小。而且，打开大量连接会消耗很多内存资源，从而引发自身的性能问题。

5. 持久连接

    1. 站点局部性：初始化了对某服务器 HTTP 请求的应用程序很可能会在不久的将来对那台服务器发起更多请求。
    2. 持久连接：HTTP/1.1 允许 HTTP 设备在事务处理结束之后将 TCP 连接保持在打开状态，以便为未来的 HTTP 请求重用现存的连接。在事务处理结束之后仍然保持在打开状态的 TCP 连接被称为持久连接。
    3. 非持久连接会在每个事务结束之后关闭，持久连接会在不同事务之间保持打开状态，直到客户端或服务器决定将其关闭为止。
    4. 重用已对服务器打开的空闲持久连接，就可以避免缓慢的连接建立阶段。已打开的连接还可以避免慢启动的拥塞适应阶段，以便更快速的进行数据的传输。
    5. 并行连接的一些缺点：
        1. 每个事务都会打开/关闭一条新的连接，会耗费时间和带宽
        2. 由于 TCP 慢启动特性的存在，每条新连接的性能都会有所降低
        3. 可打开的并行连接数量实际上是有限的
    6. 持久连接的优点：持久连接降低了时延和连接建立的开销，将连接保持在已调谐状态，而且减少了打开连接的潜在数量。但是有可能累积出大量的空闲连接，耗费本地以及远程客户端和服务器上的资源。
    7. 持久连接与并行连接配合使用是高效的方式。
    8. 实现 keep-alive：客户端可以通过包含 Connection： Keep-Alive 的首部请求将一条连接保持在打开状态。如果服务器愿意为下一条请求将连接保持在打开状态，就在响应中包含相同的首部。如果响应中没有 Connection：Keep-Alive 首部，客户端就认为服务器不支持 keep-alive，会在发回响应报文之后关闭连接。
    9. Keep-Alive 选项：
        1. timeout 参数：它估计了服务器希望将连接保持在活跃状态的时间，不是一个承诺值。
        2. max 参数：它估计了服务器还希望为多少事务保持此连接的活跃状态，不是一个承诺值。
    10. 在 HTTP/1.0 中，Keep-Alive 不是默认使用的，需要客户端发送 Connection：Keep-Alive 激活。
    11. HTTP/1.1 逐渐停止了对 keep-alive 连接的支持，用一种名为持久连接的改进型设计取代了它。持久连接的目的与 keep-alive 连接的目的相同，但工作机制更优一些。
    12. HTTP/1.1 持久连接在默认情况下是激活的。如果要在事务处理结束之后将连接关闭，需要添加首部 Connection：close。不发送 Connection：close 也不意味着服务器承诺连接永远保持在打开状态。

6. 管道化连接：

    1. HTTP/1.1 允许在持久连接上可选地使用请求管道。在响应到达之前，可以将多条请求放入队列。当第一条请求通过网络流向地球另一端的服务器时，第二条和第三条请求也可以开始发送了。在高时延网络条件下，这样做可以降低网络的环回时间，提高性能。
    2. 管道化连接的几个限制：
        1. 必须确认连接是持久的
        2. 必须按照与请求相同的顺序回送 HTTP 响应。HTTP 报文中没有序列号标签，如果收到的响应失序了，就无法与请求匹配。
        3. HTTP 客户端必须做好连接会在任意时刻关闭的准备，还要准备好重发所有未完成的管道化请求。
        4. HTTP 客户端不应该用管道化的方式发送会产生副作用的请求（比如 POST）。由于无法安全地重试 POST 这样的非幂等请求，所以出错时，就存在某些方法永远不会被执行的风险。

7. 关闭连接的奥秘
